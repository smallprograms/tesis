When an scene is beign scanned with a laser, time of flight camera, structured 
light sensor or other device capable of obtain a depth map of the scene.
 A set of 3D points is obtained per capture, its 3D coordinates 
are relative to the scanning device. Its necessary to move the captured points, 
according to the device movement or rotation in order to maintain geometrical properties of the captured scene,
 positioning the 3D points on a common coordinate system, conserving 
the original scene structure. 

This problem becomes trivial if we know the device position and orientation 
for each capture or if we have a set of matches (common points)  between each two sucesive 
captures. But this not occur in practice and additional problems arise due 
to the noise and imperfections of capturing devices.


In general, when the sensor is collecting the 3D points from the scene, 
 its necessary to move or rotate it in order to capture new objects and surfaces,
 adding more information to the reconstructed model. But in order to be 
able to infer the correct position of each capture, is necessary to have part 
of the view in common between two captures (an overlaping area). Thus is posible to position a 
new capture with respect to an old one in the scene, using this overlaping 
area to correctly align both captures.
 
The overlaping areas of the different captures of a scene must be correctly 
aligned when registering the points in a common coordinate system, 
thus with each new capture more information is added to the scene, 
getting closer to the desired result. 

\subsection{Mathematical definition}

A point cloud is a set of 3D euclidean space points and the problem of aligninig several point clouds 
in order to form a complete 3D model, where intersecting areas overlap perfectly, 
is known as registration. Assumming that all point clouds form part of a 3D global model and they can be 
 positioned  consistenly accord to this model.

Let  ${a_i},{b_i} \in \mathbb{R}^3;i = 1,2,...,N$ be two sets of 3D euclidean space points.

We want to find $R,\vec{t}$ that minimizes the following expression:
$$
\sum\limits_{i=1}^N || Ra_i - b_i - \vec{t} ||
$$

Where $R$ is a  $3x3$ rotation matrix and $\vec{t} \in \mathbb{R}^3$ is a translation vector.


In the case that the two sets are identical, the previous expression will have a minimum at zero.

We are interested in applying this minimization scheme to real life data, specifically to consecutive 
point clouds (with very small rotation and translation), registering a global 3D model of 
a real scene. In order to beign able to align this point clouds, it is necessary to have an important overlapping 
area which is equivalent to have a very small rotation and translation of the sensor registering the point clouds, 
because this area will allow to minimize distances between pairs of points corresponding to the same real world position.


\begin{figure}[!h]
\begin{center}
\includegraphics[scale=0.35]{images/two_clouds}
\caption{Two point clouds corresponding to a real life scene. We want to find the correct rotation and translation to align both point clouds.}
\end{center}
\end{figure}

