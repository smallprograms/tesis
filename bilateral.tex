\section{Bilateral Filter}


The depthmaps captured by a low cost RGB-D camera usually contains noise, this can be 
consecuence of materials reflectance, device imperfections, object fast movement, distance to the 
sensor, etc. 

In order to reduce the effect of noise is natural to use some kind of filter, as usual in computer 
vision, a typical filter will take information of a pixel and its neighboorhod to generate a result. 
If the image is smooth, without abrupt changes in intensity, a simple average could be enough. However, this 
is not the case in the presence of edges or corners, areas where the intensity changes charply. 
The bilateral filter afronts this problem, giving to each neighboor a weight based on its cercany  
to the center pixel. In a grayscale image it takes into account 
the neighboor intensity distance and location distance (in image plane) to calculate the weight.  A depthmap is very similar to a grayscale 
image, the only difference is that the depth map represents geometrical information and usually contains holes 
(areas where the sensor failed to capture distance). 

A bileateral filter was applied to the depth maps, using the euclidean distance and the distance along the z axis to calculate 
the weight of each pixel neighboor in the depth map.

In a filter window centered at pixel location $(x,y)$, the weighted average was calculated using the following weight for each neighboor:


$$ w(p,q,\sigma_d,\sigma_z) = k(d(p,q),\sigma_d) k(z(p,q),\sigma_z). $$

\noindent Where 

$$ k(v,\sigma) = \frac{e^{-v^2}}{2*\sigma^2}, $$
$$ d(p,q) = ||p - q||, $$
$$ z(p,q) = |p_z - q_z|, $$
$$ p = (p_x,p_y,p_z), $$ 
$$ q = (q_x,q_y,q_z). $$

\noindent p is the central point 3D coordinate and q the 3D coordinate of one of its neighboors. 3D coordinates are obtained using
 the depth map and equations \ref{eq:depthmapx} and \ref{eq:depthmapy}.  Each point has a weight that depends on its euclidean distance and
 the distance along the z axis, to the central point. The parameter $\sigma_d$ defines 
the neighborhood, all points of the depthmap that are at euclidean distance $2*\sigma_d$ or less from the central pixel are considered.


Let 


$$ W = \sum\limits_{q \in neighborhood} {w(d,\sigma_d,z,\sigma_z)},$$

\noindent the final value of the center pixel is then

$$p_z = \frac{1}{W}\sum\limits_{q \in neighborhood}{w(d,\sigma_d,z,\sigma_z)p_z}.$$

\noindent where the neighborhood is conformed by the points at an euclidean distance less than $2*\sigma_d$.

After applying this filter we obtain an smoothed version of the depth map, without loosing edges and important geometrical information.
A detailed explanation of the bilateral filter can be found in \cite{TomasiBilateral}.

\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.35]{images/bilateral}
\end{center}
\caption{Left: Point cloud without filtering Right: Point cloud with bilateral filtering. Noticeable effects at first sight next to the borders of objects}
\end{figure}

