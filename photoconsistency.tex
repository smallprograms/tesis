\section{Photoconsistency}

Having a estimation of rotation R and translation t, it is possible to reproject the 3D points to the 2D image plane using the 
camera parameters. If we have a point $p=(X,Y,Z)$ we can project it to the image plane using the following formula obtained 
from the pinhole camera model:

\begin{equation}
U(p) = (\frac{fX}{Z} - c_x, \frac{fY}{Z} - cy)
\label{eq:reproject}
\end{equation}

Where $f$ and $(cx,cy)$ denote the focal length and optical center of the pinhole camera model. 
We can apply the transformation R,t to the point before projecting it:

\begin{equation}
T(R,t,p) = Rp + t = p'
\end{equation}

Image coordinates  $p'$ are used to obtain image color in the target image, making a reprojection of $p'$ to the image plane.

Then we can apply the following error formula, that represents the color differences between the reprojected image and 
the target image. 

\begin{equation}
E(R,t) = \frac{1}{N} \sum\limits_{p \in pointCloudSource} |RGBsource(U(p)) - RGBtarget(U(p'))|
\end{equation}


Where:
\begin{itemize}
\item N is the number of points.
\item $U(p)$ is the reprojection function \ref{eq:reproject} that returns (x,y) image coordinates of an (X,Y,Z) point.
\item  $RGBsource(x,y)$ is function that returns a vector (R,G,B) representing image color at location (x,y). Where 
R,G,B are positive integers between 0 and 255. The same holds for $RGBtarget(x,y)$. Both functions represent 
source and target images respectively.
\end{itemize}

In this case the average color difference vector norm is used, but there are many ways of measure photoconsistency, 
for example using a color space different from RGB or using another error metric. Photoconsistency is widely used in 3D reconstuction, for example some works using it are \cite{Whelan13},\cite{kerl13icra} and \cite{Newcombe10livedense}

