%%%%%%%%%%%%Accounting v/s Monitoring
%https://twiki.grid.iu.edu/bin/view/Accounting/WebHome
%For monitoring,the goal is to have a view of the current status of the system with minimal delay. Small numerical errors, approximation and statistical estimation in the data are not fatal for monitoring. For example if a CPU is utilized at 82% or 85% does not matter to the monitoring system. For monitoring, missing informatio is not really an issue. For example, the measurement of the cpu load is not really affected if we are missing a few samples.

%For accounting, the goal is to have an accurate view of the resource and service usage in the system. This includes linking them to the individual user request. The accounting should not loss any accounting data or record. The main focus is on the historical view and a delay in the information is acceptable. However the information need to be as accurate as possible, and include an estimate of its accuracy. The accounting system need to be able to support the development of an economic mode.

%The type of information and the means of collecting this information are similar between monitoring and accounting but the choices of trade-offs are clearly different; for example timeliness vs. accuracy and completeness.

The {\itshape Accounting System} is a component of a grid middleware,
which purpose is to provide an accurate view of the resource and
service usage in the system. 

At the ATLAS grid there exists three different Accounting Systems:
APEL, GRATIA and SGAS, which belong to EGEE, OSG and NDGF sub-grid
respectively.

The {\itshape ATLAS Accounting System} works one level above the
previously mentioned accounting systems, because the main idea of this
system, is to provide a global view of the accounting data of the
ATLAS grid (not separated per sub-grid) and also to provide the
information in different formats and specific views (considering the
ATLAS topology) in order to be used mainly by the {\itshape resource
management board} of ATLAS grid, but because of the flexibility of the
system, this may be used also by other users or other applications of
the ATLAS grid.




\section{Accounting Grid}

In a grid environment, the computing resources, the application data
and the users belonging to a Virtual Organization (VO) are
distributed. Jobs submitted by the users may be sent to computing
resources close to the data or may go to remote resources with
available job slots, thus reducing queue times. As a consequence, jobs
that run on a grid environment must be properly accounted for. The
usage of resources (CPU time, wall-clock time and memory) and the
resources provided by sites, all as a function of time, can then be
easily determined as well \cite{accLHC}.

The data of the usage of the grid resources, which includes CPU times,
wall clock times, number of jobs, storages, etc., is generically
called {\itshape accounting data}.


The multigrid environment of ATLAS implies that each sub-grid contains
its own middleware and hence, its own Accounting System, which are
described as follows:


\begin{description}
\item[APEL]\cite{APEL}
({\bf A}ccounting {\bf P}rocessor for {\bf E}vents {\bf L}ogs)
is the accounting tool used by EGEE, which filters the accounting
information from the log files generated by a site and build
accounting records.
The accounting data stored in APEL uses a fine-grained schema and is
used to describe accounting information at the job level i.e. CPU
time, wall clock time, memory, dn, vo, etc.

The collection of accounting records is done through
R-GMA, an implementation of the Grid Monitoring
Architecture (GMA) proposed by the GGF (Global Grid Forum)
 \cite{OGF}.
GMA models has a a set of {\itshape consumers}, which request the
information, {\itshape producers}, which provides the information, and a
{\itshape registry}, which allows the communication between producers and
consumers.
The EGGE sites publish their own accounting data using a
{\itshape producer} and its locally assigned R-GMA server.
To collect data from all participating sites, the data is streamed to
a centralized database via a secondary producer.

APEL processes gatekeeper and batch system logs to produce accounting
records.
Currently supports PBS and LSF batch systems but can be easily
extended to other batch systems as well.
APEL systems allows the visualization of the accounting data in a web
application and generates summaries of resource usage of all the EGEE
sites.

\begin{figure}[h!tbp]
\centering
\pgfuseimage{apel}
% \epsfig{file=images/apel.eps,scale=0.3}
\caption{Data collection process done by APEL.}
\label{fig:apel}
\end{figure}


\item
[GRATIA]\cite{GRATIA} is the accounting system used by OSG, which
designs and deploys robust, scalable, trustable and dependable grid
accounting, publishes an interface to the services and provides a
reference implementation. 
The main goal for GRATIA is to track VO members' resource usage and to
present that information in a consistent {\itshape grid-wide view},
focusing in particular on CPU and Disk Storage utilization.

This accounting system is composed of four main parts:
\begin{itemize}
\item Collection of accounting data.
\item Interface between collectors and the accounting database.
\item Sets of distributed data stores contained the accounting
      information.
\item Interface to publish the accounting information containing in
      the databases.
\item A presentation layer giving access to report and aggregates
      information.
%\item A presentation layer giving access to report and aggregates
%      information
\end{itemize}

\item
[SGAS] \cite{SGAS} (\textbf{S}we\textbf{G}rid \textbf{A}ccounting
\textbf{S}ystem) is the accounting system used by NDGF, which is based
on open, standard Grid and Web services protocols and it has a
particular focus on shared quota enforcement across organizational
boundaries, security and simplicity of deployment.

The main components of SGAS are a bank service, which provides most of
the accounting functionality, a workload management integration
component and a usage tracking service. Figure \ref{fig:sgas} shows an
overview of SGAS.

\begin{figure}[h!tbp]
\centering
\pgfuseimage{sgas}
% \epsfig{file=images/apel.eps,scale=0.3}
\caption{SGAS components}
\label{fig:sgas}
\end{figure}

The operation flow is as follow: a user submits a job (potentially via
a brokering service) to a workload manager service running on the
resource. The resource integration component intercepts the request by
way of a workload manager plugin, and it interacts with the bank to
reserve sufficient quota.
%, and it considers the following
%main components: users, VOs, projects, resources, bank services, log
%and usage services.
%The last ones hold detailed information about the resources consumed
%(Usage Records URs), job status, input data, output data, etc., about
%the jobs submitted by the VO users.
\end{description}





\section{Accounting in the ATLAS Grid}

It has been described the three accounting systems belonging to each
sub-grid of ATLAS.
Currently, APEL publishes accounting data of EGEE and OSG sites in a
web application, but still there is the need to have a global view of
the usage of the all resources and the visualization should be
available in different formats and structured as the ATLAS topology,
considering the different tiers and clouds that form the whole ATLAS
grid. 
Furthermore, the existing systems, APEL, GRATIA and SGAS, store
accounting data for all LHC experiments. 
More precisely, they are not restricted exclusively to the ATLAS
experiment.  
In fact, ATLAS did not have its own system for deploying the relevant
information as required by the managers of the experiment, so that a
real need for an ATLAS specific Accounting System existed. 
The proposed {\itshape ATLAS Accounting System} describes in this
section, satisfies that need.

The ATLAS Accounting System allows: 
\begin{itemize}
\item to retrieve accounting data from different sources and from the
      different sub-grids
\item to process the collected data and to store it into a centralized
      database, and
\item to display the information to the users in different formats,
      thus providing a "topological view" of the whole grid and
      sub-grids
\item In addition, the system also allows to add new sources of
      information in an easy way due to the modular implementation
\end{itemize}


\begin{figure}
\centering
\pgfuseimage{accsys}
\caption{ATLAS Accounting System Architecture}
\label{fig:accsys}
\end{figure}

The implementation of the system was done using the Dashboard
Framework.  
The {\itshape arda.dashboard.apel} is the new module developed that
implements ATLAS Accounting System.

The accounting data is retrieved using the apel.collector service,
which gets the information from an accounting data source, and then it
stores it in a local database.


\subsection{Database Schema}
The schema of the database is simple, it has three tables:
{\itshape sumCPU}, {\itshape site} and {\itshape InsertRecord}.
The first one stores ATLAS's accounting data, 
%the  {\itshape site}
%table contains attributes related with the topology and site of the
%ATLAS grid, and finally, InsertRecord stores the timestamp of each
%insertion into the {\itshape sumCPU} table.
the second one, the {\itshape site} table contains attributes related with the topology 
of the ATLAS grid, and finally, InsertRecord stores the timestamp of each
insertion into the {\itshape sumCPU} table.

\begin{figure}[h!tbp]
\centering
\pgfuseimage{databaseSchemaAPEL}
% \epsfig{file=images/databaseSchema.eps,scale=0.5}
\caption{ATLAS Accounting System Database Schema}
\label{fig:dbSchema}
\end{figure}

The primary key of the sumCPU table has the following fields:
ExecutingSite,
LCGUserVO,
Month and
Year,
and this makes possible to maintain aggregated
monthly accounting data for each site
(belonging to a VO, in this case always ATLAS VO).


The accounting data retrieved from the different sources can have
different {\itshape granularity}.
For instance, APEL has a {\itshape monthly granularity}.
This means that the records with aggregated data to which APEL gives
access, have aggregation-coverage of one month each.
More precisely, APEL filters the log files produced for each site,
to build the accounting records and then continuously aggregates the
accounting data of each job sent to the grid.
For instance, a particular APEL accounting record can represent
that in June 2008 site A used, say, 272394 hours of CPU,
and in the same month site B used, say, 1055 hours of CPU.\\
On the other hand, GRATIA allows the access of accounting records in
a per {\itshape job granularity}.
For instance, job X sent by Site A used, say, 2 hours of CPU on
June 24th, 2008.
The ATLAS Accounting System maintains a monthly granularity (like
APEL).
Thus, when accounting data is retrieved from GRATIA, it is necessary
to process this data in a way that insures that the output granularity
is the same as the one defined in the database schema.
(Fig. \ref{fig:dbSchema}).


\subsection{Components}
The {\itshape arda.dashboard.apel} is the dashboard module that
implements the ATLAS Accounting System, and it has the following
components:
%files and directories structure:

%\begin{table}[h!tpb]
%\begin{tabularx}{450pt}{>{\hsize=0.15\hsize}X>{\hsize=0.85\hsize}X}
%setup.py        &Main distutils setup file \\
%%setup.cfg      &Distutils configuration (default parameters for the
%%different distutils commands)\\
%%module.cfg     &Module properties. This is a way to store in an
%%external file the information that is usually passed directly to the
%%distutils setup method. Only used if the the dashboard specific setup
%%method is invoked, instead of the default distutils setup. This
%%custom setup is simply loading properties from this file and then
%%invoking the default setup\\
%%MANIFEST.in    &Additional files (not libraries) to include in the
%%package (RPM, tarballs, ...)\\
%%LICENSE        &The license of this package\\
%%README &Contains some details about the packages (might include links
%%to the manual, or just contain the manual inside of it - if the
%%default docbook documentation is not being used)\\
%%RELEASE-NOTES  &Keeps track of the package evolution. On every
%%release (major, minor, patch or candidate) a new entry is added
%%describing the changes (provides all details about package
%%releases)\\
%/config (dir)   &Package configuration files. Usually each module will
%have additional configuration files stored in this area, but at least
%one directory following the package name should exist\\
%/doc (dir)      &Holds the package documentation. This includes
%different sub-directories, namely: guides, for user guides like this
%one; man, for command line tool man pages\\
%/lib (dir)      &All the package libraries should goes here.\\
%/templates (dir)        &Optional directory holding the web
%application static files (web pages, xsl stylesheets, images)\\
%/build (dir)    &Temporary directory created for build files\\
%\end{tabularx}
%\end{table}


%The {\itshape setup.py} file is a configuration file that contains the
%definitions of the packages (located in the {\itshape lib} directory)
%and files related with the application's interface of the {\itshape
%arda.dashboard.apel} module. As follows, we describes the main
%packages of this module (the complete documentation can be found in
%\cite{bib:AccSysDoc}).

\begin{itemize}
\item
{\itshape dashboard.dao.oracle.apel}: This component allows the
management of the application's database.
\item
{\itshape dashboard.http.actions.apel}: This component contains the
entities in charge of request of data playing as the
interface between the user (or other application)
and the data layer.
\item
{\itshape dashboard.http.views.apel}: It allows
the display of accounting data
in a particular format.
In particular, it can display the accounting information as pie
plots.
\item
{\itshape dashboard.collector.apel}.
This component allows to retrieve the accounting data from an external
sources of information (APEL, GRATIA) and store this data into the
own application's database.
The collector is constantly retrieving and updating the accounting
information.
In this application it is necessary to create one collector
for each source of information.
\end{itemize}

\subsection{Accounting Data Collection}
Currently, the ATLAS Accounting System has implemented two services to
collect accounting data in an automatic and periodic manner.

\begin{description}
\item[APEL Collector]
This agent gathers accounting data from APEL.
The agent request the data using the {\itshape MySQLdb} interface
(see Fig. \ref{fig:apelCollector}), asking for the data directly to
the APEL database.
Once the data is retrieved, the APEL collector must process this data
to obtain the proper format, and later the data is stored into the
local database.
This process is done periodically and each time that the collector
retrieves the data from APEL, checks the timestamps of the previous
collection, in order to retrieve only the new accounting data,
thus avoiding the retrieval of the complete APEL accounting data
(which is a huge volume of data).

\begin{figure}[h!tbp]
\centering
\pgfuseimage{apelCollector}
%\epsfig{file=images/apelCollector.eps,scale=0.3}
\caption{APEL Collector.}
\label{fig:apelCollector}
\end{figure}



\item[Gratia Collector]
This agent gathers accounting data from GRATIA.
The request is done via an HTTP request, using the {\itshape URLClient}
object, provided by the Dashboard framework.
In contrast to APEL Collector, where we have direct access to the APEL
database, here the GRATIA agent establishes the
connection with a specified URL, and through a service provided by
GRATIA, it is possible to retrieve the accounting data in a CSV
format, for which, is necessary to format the data to insert it later
in the local database of the ATLAS Information System.
Fig. \ref{fig:gratiaCollector} depicts the mechanism to collect the
GRATIA accounting data.
\end{description}


\begin{figure}[h!tbp]
\centering
\pgfuseimage{gratiaCollector}
%\epsfig{file=images/gratiaCollector.eps,scale=0.3}
\caption{GRATIA Collector.}
\label{fig:gratiaCollector}
\end{figure}


\newpage
We have described two collectors that allow the retrieval of
accounting data from the APEL and GRATIA systems.
To collect data from new sources of information, it is necessary to
create a new collector, which has to retrieve the information and then
process it in such a way that the data can be stored in the
database, using the  schema described in
Fig. \ref{fig:dbSchema}.
The important point here is to preserve the
{\itshape monthly granularity} of the accounting data, this is the records
of accounting data stored in the local database must maintain the
primary key: ExecutingSite, VO, Month and Year.\\


Currently, the ATLAS Accounting System is a prototype, which performs
the most needed functionalities such as collection of data from the
main sources of information, providing this information in different
formats (XML, CSV, images) and also, a web application that displays
the accounting data in the ATLAS grid topology manner, considering the
sites, tiers, clouds, countries and regions that forms the whole ATLAS
grid.
The {\itshape a posteriori} an periodical analysis of the accounting
information collected and provided by the ATLAS Accounting System will
allow to improve the performance of the ATLAS grid. 
A future work includes the development appropriate metrics and
statistical tools in order to measure the efficiency of the resource
usage in the ATLAS grid.
    

As  mentioned before, the ATLAS Accounting System allows data
visualization considering the ATLAS topology, but during the
development of the ATLAS Accounting System, a serious lack of a single
system that provides information related to the resources, services
and topology of the ATLAS grid, was detected. 
In a grid environment, in particular in the ATLAS grid, it is
fundamental to have an Information System that gives information of
the whole grid, and not only by each sub-grid (which is the current
situation).
That Information System is one of the main contribution presented in
this tesis.

